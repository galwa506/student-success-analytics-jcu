{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Required Libraries "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1753789227768
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_excel('student_data_2.xlsx')\n",
        "\n",
        "# Show all columns when displaying DataFrames\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "   student_id                             course student_cohort  \\\n0           1  Master of Business Administration    SRI to JCUB   \n1           2  Master of Business Administration     Continuing   \n2           3  Master of Business Administration     First year   \n3           4  Master of Business Administration            New   \n4           5  Master of Business Administration     Continuing   \n\n  academic_status failed_subjects        study_skills(attended)  \\\n0         At Risk             NaN              Essential Skills   \n1        Excluded             NaN                   Referencing   \n2         At Risk             NaN                       Writing   \n3        Excluded             NaN              Essential Skills   \n4         At Risk             NaN  Essential Skills and Reading   \n\n             referral    pp_meeting self_assessment  \\\n0  Student Counsellor        Booked             Yes   \n1    Student Advocate  Not relevant             Yes   \n2          Enrollment      Attended             Yes   \n3    Student Advocate      Attended              No   \n4  Student Counsellor  Not relevant              No   \n\n  readiness_assessment_results follow_up follow_up_type  subject_1  \\\n0       L/G:9/10 N:5/10 R:8/10       Yes       No Reply        NaN   \n1       L/G:9/10 N:5/10 R:8/10        No          Phone        NaN   \n2       L/G:9/10 N:5/10 R:8/10       Yes          Phone        NaN   \n3       L/G:9/10 N:5/10 R:8/10        No            F2F        NaN   \n4       L/G:9/10 N:5/10 R:8/10       Yes       No Reply        NaN   \n\n   subject_1_assess_1  subject_1_assess_2  subject_1_assess_3  \\\n0                7.70               27.22               26.51   \n1               31.14               54.66               81.72   \n2               39.09               75.39               84.62   \n3               88.59               84.36                3.79   \n4                0.98               13.80               53.40   \n\n   subject_1_assess_4  attendance_1 learn_jcu_issues_1  lecturer_referral_1  \\\n0               50.09            20             Access  Concern for Welfare   \n1                1.96             9             Access       Non Submission   \n2               82.66            51          No Access           Attendance   \n3               26.05            34             Access  Concern for Welfare   \n4               39.69            45             Access           Attendance   \n\n   subject_2  subject_2_assess_1  subject_2_assess_2  subject_2_assess_3  \\\n0        NaN               69.33               44.44               11.39   \n1        NaN               95.23               48.61               14.68   \n2        NaN               86.20               98.80               71.57   \n3        NaN                7.69               25.96               49.83   \n4        NaN               60.51               57.47               15.80   \n\n   subject_2_assess_4  attendance_2 learn_jcu_issues_2  lecturer_referral_2  \\\n0               18.78            41             Access           Attendance   \n1               44.77            66          No Access  Concern for Welfare   \n2               96.08            64          No Access  Concern for Welfare   \n3               17.77            57             Access       Non Submission   \n4               33.59             3          No Access  Concern for Welfare   \n\n   subject_3  subject_3_assess_1  subject_3_assess_2  subject_3_assess_3  \\\n0        NaN               39.02               17.71               94.50   \n1        NaN                3.72               38.52               25.80   \n2        NaN               77.77               77.27               81.95   \n3        NaN               95.41                8.93                3.21   \n4        NaN               90.12               52.18               36.05   \n\n   subject_4_assess_4  attendance_3 learn_jcu_issues_3  lecturer_referral_3  \\\n0                9.83            89             Access       Non Submission   \n1               11.80           100          No Access       Non Submission   \n2               62.35            42             Access           Attendance   \n3               99.15            51             Access  Concern for Welfare   \n4               20.65            19             Access  Concern for Welfare   \n\n                                            comments     identified_issues  \n0  Week 8. Student re-engaged with tutorials. Sub...       Late Enrollment  \n1  booked to see a doctor. Week 5. Student contac...  Poor time management  \n2  Week 8. Student re-engaged with tutorials. Sub...  Poor time management  \n3  Week 6. Student submitted assessment late. Ext...       Death in family  \n4  Week 3 late enrolment. Student finding it diff...              Sickness  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>course</th>\n      <th>student_cohort</th>\n      <th>academic_status</th>\n      <th>failed_subjects</th>\n      <th>study_skills(attended)</th>\n      <th>referral</th>\n      <th>pp_meeting</th>\n      <th>self_assessment</th>\n      <th>readiness_assessment_results</th>\n      <th>follow_up</th>\n      <th>follow_up_type</th>\n      <th>subject_1</th>\n      <th>subject_1_assess_1</th>\n      <th>subject_1_assess_2</th>\n      <th>subject_1_assess_3</th>\n      <th>subject_1_assess_4</th>\n      <th>attendance_1</th>\n      <th>learn_jcu_issues_1</th>\n      <th>lecturer_referral_1</th>\n      <th>subject_2</th>\n      <th>subject_2_assess_1</th>\n      <th>subject_2_assess_2</th>\n      <th>subject_2_assess_3</th>\n      <th>subject_2_assess_4</th>\n      <th>attendance_2</th>\n      <th>learn_jcu_issues_2</th>\n      <th>lecturer_referral_2</th>\n      <th>subject_3</th>\n      <th>subject_3_assess_1</th>\n      <th>subject_3_assess_2</th>\n      <th>subject_3_assess_3</th>\n      <th>subject_4_assess_4</th>\n      <th>attendance_3</th>\n      <th>learn_jcu_issues_3</th>\n      <th>lecturer_referral_3</th>\n      <th>comments</th>\n      <th>identified_issues</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Master of Business Administration</td>\n      <td>SRI to JCUB</td>\n      <td>At Risk</td>\n      <td>NaN</td>\n      <td>Essential Skills</td>\n      <td>Student Counsellor</td>\n      <td>Booked</td>\n      <td>Yes</td>\n      <td>L/G:9/10 N:5/10 R:8/10</td>\n      <td>Yes</td>\n      <td>No Reply</td>\n      <td>NaN</td>\n      <td>7.70</td>\n      <td>27.22</td>\n      <td>26.51</td>\n      <td>50.09</td>\n      <td>20</td>\n      <td>Access</td>\n      <td>Concern for Welfare</td>\n      <td>NaN</td>\n      <td>69.33</td>\n      <td>44.44</td>\n      <td>11.39</td>\n      <td>18.78</td>\n      <td>41</td>\n      <td>Access</td>\n      <td>Attendance</td>\n      <td>NaN</td>\n      <td>39.02</td>\n      <td>17.71</td>\n      <td>94.50</td>\n      <td>9.83</td>\n      <td>89</td>\n      <td>Access</td>\n      <td>Non Submission</td>\n      <td>Week 8. Student re-engaged with tutorials. Sub...</td>\n      <td>Late Enrollment</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Master of Business Administration</td>\n      <td>Continuing</td>\n      <td>Excluded</td>\n      <td>NaN</td>\n      <td>Referencing</td>\n      <td>Student Advocate</td>\n      <td>Not relevant</td>\n      <td>Yes</td>\n      <td>L/G:9/10 N:5/10 R:8/10</td>\n      <td>No</td>\n      <td>Phone</td>\n      <td>NaN</td>\n      <td>31.14</td>\n      <td>54.66</td>\n      <td>81.72</td>\n      <td>1.96</td>\n      <td>9</td>\n      <td>Access</td>\n      <td>Non Submission</td>\n      <td>NaN</td>\n      <td>95.23</td>\n      <td>48.61</td>\n      <td>14.68</td>\n      <td>44.77</td>\n      <td>66</td>\n      <td>No Access</td>\n      <td>Concern for Welfare</td>\n      <td>NaN</td>\n      <td>3.72</td>\n      <td>38.52</td>\n      <td>25.80</td>\n      <td>11.80</td>\n      <td>100</td>\n      <td>No Access</td>\n      <td>Non Submission</td>\n      <td>booked to see a doctor. Week 5. Student contac...</td>\n      <td>Poor time management</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Master of Business Administration</td>\n      <td>First year</td>\n      <td>At Risk</td>\n      <td>NaN</td>\n      <td>Writing</td>\n      <td>Enrollment</td>\n      <td>Attended</td>\n      <td>Yes</td>\n      <td>L/G:9/10 N:5/10 R:8/10</td>\n      <td>Yes</td>\n      <td>Phone</td>\n      <td>NaN</td>\n      <td>39.09</td>\n      <td>75.39</td>\n      <td>84.62</td>\n      <td>82.66</td>\n      <td>51</td>\n      <td>No Access</td>\n      <td>Attendance</td>\n      <td>NaN</td>\n      <td>86.20</td>\n      <td>98.80</td>\n      <td>71.57</td>\n      <td>96.08</td>\n      <td>64</td>\n      <td>No Access</td>\n      <td>Concern for Welfare</td>\n      <td>NaN</td>\n      <td>77.77</td>\n      <td>77.27</td>\n      <td>81.95</td>\n      <td>62.35</td>\n      <td>42</td>\n      <td>Access</td>\n      <td>Attendance</td>\n      <td>Week 8. Student re-engaged with tutorials. Sub...</td>\n      <td>Poor time management</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Master of Business Administration</td>\n      <td>New</td>\n      <td>Excluded</td>\n      <td>NaN</td>\n      <td>Essential Skills</td>\n      <td>Student Advocate</td>\n      <td>Attended</td>\n      <td>No</td>\n      <td>L/G:9/10 N:5/10 R:8/10</td>\n      <td>No</td>\n      <td>F2F</td>\n      <td>NaN</td>\n      <td>88.59</td>\n      <td>84.36</td>\n      <td>3.79</td>\n      <td>26.05</td>\n      <td>34</td>\n      <td>Access</td>\n      <td>Concern for Welfare</td>\n      <td>NaN</td>\n      <td>7.69</td>\n      <td>25.96</td>\n      <td>49.83</td>\n      <td>17.77</td>\n      <td>57</td>\n      <td>Access</td>\n      <td>Non Submission</td>\n      <td>NaN</td>\n      <td>95.41</td>\n      <td>8.93</td>\n      <td>3.21</td>\n      <td>99.15</td>\n      <td>51</td>\n      <td>Access</td>\n      <td>Concern for Welfare</td>\n      <td>Week 6. Student submitted assessment late. Ext...</td>\n      <td>Death in family</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Master of Business Administration</td>\n      <td>Continuing</td>\n      <td>At Risk</td>\n      <td>NaN</td>\n      <td>Essential Skills and Reading</td>\n      <td>Student Counsellor</td>\n      <td>Not relevant</td>\n      <td>No</td>\n      <td>L/G:9/10 N:5/10 R:8/10</td>\n      <td>Yes</td>\n      <td>No Reply</td>\n      <td>NaN</td>\n      <td>0.98</td>\n      <td>13.80</td>\n      <td>53.40</td>\n      <td>39.69</td>\n      <td>45</td>\n      <td>Access</td>\n      <td>Attendance</td>\n      <td>NaN</td>\n      <td>60.51</td>\n      <td>57.47</td>\n      <td>15.80</td>\n      <td>33.59</td>\n      <td>3</td>\n      <td>No Access</td>\n      <td>Concern for Welfare</td>\n      <td>NaN</td>\n      <td>90.12</td>\n      <td>52.18</td>\n      <td>36.05</td>\n      <td>20.65</td>\n      <td>19</td>\n      <td>Access</td>\n      <td>Concern for Welfare</td>\n      <td>Week 3 late enrolment. Student finding it diff...</td>\n      <td>Sickness</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1753789228228
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Cleaning and Exploration"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a concise summary of the DataFrame, including column names, data types, non-null counts, and memory usage.\n",
        "df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 698 entries, 0 to 697\nData columns (total 38 columns):\n #   Column                        Non-Null Count  Dtype  \n---  ------                        --------------  -----  \n 0   student_id                    698 non-null    int64  \n 1   course                        698 non-null    object \n 2   student_cohort                698 non-null    object \n 3   academic_status               698 non-null    object \n 4   failed_subjects               33 non-null     object \n 5   study_skills(attended)        698 non-null    object \n 6   referral                      698 non-null    object \n 7   pp_meeting                    698 non-null    object \n 8   self_assessment               698 non-null    object \n 9   readiness_assessment_results  698 non-null    object \n 10  follow_up                     698 non-null    object \n 11  follow_up_type                698 non-null    object \n 12  subject_1                     0 non-null      float64\n 13  subject_1_assess_1            698 non-null    float64\n 14  subject_1_assess_2            698 non-null    float64\n 15  subject_1_assess_3            698 non-null    float64\n 16  subject_1_assess_4            698 non-null    float64\n 17  attendance_1                  698 non-null    int64  \n 18  learn_jcu_issues_1            698 non-null    object \n 19  lecturer_referral_1           698 non-null    object \n 20  subject_2                     0 non-null      float64\n 21  subject_2_assess_1            698 non-null    float64\n 22  subject_2_assess_2            698 non-null    float64\n 23  subject_2_assess_3            698 non-null    float64\n 24  subject_2_assess_4            698 non-null    float64\n 25  attendance_2                  698 non-null    int64  \n 26  learn_jcu_issues_2            698 non-null    object \n 27  lecturer_referral_2           698 non-null    object \n 28  subject_3                     0 non-null      float64\n 29  subject_3_assess_1            698 non-null    float64\n 30  subject_3_assess_2            698 non-null    float64\n 31  subject_3_assess_3            698 non-null    float64\n 32  subject_4_assess_4            698 non-null    float64\n 33  attendance_3                  698 non-null    int64  \n 34  learn_jcu_issues_3            698 non-null    object \n 35  lecturer_referral_3           698 non-null    object \n 36  comments                      698 non-null    object \n 37  identified_issues             698 non-null    object \ndtypes: float64(15), int64(4), object(19)\nmemory usage: 207.3+ KB\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1753789228293
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename Columns\n",
        "df.rename(columns={'subject_4_assess_4':'subject_3_assess_4'}, inplace=True)\n",
        "df.columns"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "Index(['student_id', 'course', 'student_cohort', 'academic_status',\n       'failed_subjects', 'study_skills(attended)', 'referral', 'pp_meeting',\n       'self_assessment', 'readiness_assessment_results', 'follow_up',\n       'follow_up_type', 'subject_1', 'subject_1_assess_1',\n       'subject_1_assess_2', 'subject_1_assess_3', 'subject_1_assess_4',\n       'attendance_1', 'learn_jcu_issues_1', 'lecturer_referral_1',\n       'subject_2', 'subject_2_assess_1', 'subject_2_assess_2',\n       'subject_2_assess_3', 'subject_2_assess_4', 'attendance_2',\n       'learn_jcu_issues_2', 'lecturer_referral_2', 'subject_3',\n       'subject_3_assess_1', 'subject_3_assess_2', 'subject_3_assess_3',\n       'subject_3_assess_4', 'attendance_3', 'learn_jcu_issues_3',\n       'lecturer_referral_3', 'comments', 'identified_issues'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1753789228353
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Clean Course Data\n",
        "\n",
        "This section standardizes course names and maps each student's course to a corresponding set of subject codes. It corrects inconsistencies in course naming, then assigns three subject codes per student based on their enrolled course, ensuring a consistent and accurate subject representation in the dataset."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['course'] = df['course'].str.strip().str.lower()\n",
        "df['course'].unique()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "array(['master of business administration',\n       'master of education - master of business administration',\n       'master of information technology', 'bachelor of business',\n       'master of engineering management',\n       'bachelor of information technology',\n       'master of professional accounting',\n       'master of international tourism and hospitality management',\n       'bachelor of tourism, hospitality and events',\n       'master of professional account and master of business administration',\n       'bachelor of commerce',\n       'master of international tourism and hospitality management - master of business administration',\n       'master of data science (professional)',\n       'master of information technology - master of business administration',\n       'postgraduate qualifying program - business'], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1753789228420
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map subject code to subject names using Dictionary\n",
        "subject_dict = {\n",
        "    \"BU1002\": \"Accounting for Decision Making\",\n",
        "    \"BU1003\": \"Principles of Economics\",\n",
        "    \"BU1007\": \"Principles of Data Analysis for Business\",\n",
        "    \"BU1112\": \"Business Law\",\n",
        "    \"BX2011\": \"Foundation of Accounting Principles\",\n",
        "    \"BX2014\": \"Principles of Finance\",\n",
        "    \"CP1401\": \"Fundamentals of Problem Solving and Programming I\",\n",
        "    \"CP1402\": \"Internet Fundamentals\",\n",
        "    \"CP1404\": \"Programming II\",\n",
        "    \"TO1008\": \"Introduction to Tourism, Hospitality and Events Management\",\n",
        "    \"TO2117\": \"Food and Beverage Management\",\n",
        "    \"TO3052\": \"Experience Design for Tourism Hospitality and Events\",\n",
        "    \"LB5113\": \"Corporate Strategy\",\n",
        "    \"LB5202\": \"Marketing Essentials\",\n",
        "    \"LB5205\": \"People in Organisations\",\n",
        "    \"MA5831\": \"Advanced Data Management and Analysis using SAS\",\n",
        "    \"MA5840\": \"Data Science and Strategic Decision Making for Business\",\n",
        "    \"MA5851\": \"Data Science Master Class 1\",\n",
        "    \"ED5097\": \"Research Design and Proposal\",\n",
        "    \"ED5880\": \"Educational Leadership\",\n",
        "    \"EG5200\": \"Career Planning\",\n",
        "    \"EG5220\": \"Advanced Asset Management and Reliability\",\n",
        "    \"EG5310\": \"Professional Placement\",\n",
        "    \"CP5046\": \"ICT Project 1: Analysis and Design\",\n",
        "    \"CP5047\": \"ICT Project 2: Implementation and Commissioning\",\n",
        "    \"CP5503\": \"Enterprise Database Systems - Oracle\",\n",
        "    \"TO5101\": \"Tourism Systems Analysis\",\n",
        "    \"TO5103\": \"Global Destinations and Competitiveness\",\n",
        "    \"TO5104\": \"Tourist Management Strategies\",\n",
        "    \"CO5117\": \"Introduction to Accounting\",\n",
        "    \"CO5103\": \"Management Accounting\",\n",
        "    \"CO5109\": \"Corporate Finance\",\n",
        "    \"LB5203\": \"Sustainable Enterprise\",\n",
        "    \"LB5212\": \"Accounting and Finance for Managers\"\n",
        "}\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1753789228475
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the subject name from the subject code\n",
        "subject_dict['BU1007'] # Output: Principles of Data Analysis for Business "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'Principles of Data Analysis for Business'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1753789228561
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map each course to a list of three subject codes\n",
        "course_subjects = {\n",
        "    'Bachelor of Business': ['BU1002', 'BU1003', 'BU1007'],\n",
        "    'Bachelor of Commerce': ['BU1112', 'BX2011', 'BX2014'],\n",
        "    'Bachelor of Information Technology': ['CP1401', 'CP1402', 'CP1404'],\n",
        "    'Bachelor of Tourism, Hospitality and Events': ['TO1008', 'TO2117', 'TO3052'],\n",
        "    'Master of Business Administration': ['LB5113', 'LB5202', 'LB5205'],\n",
        "    'Master of Data Science (Professional)': ['MA5831', 'MA5840', 'MA5851'],\n",
        "    'Master of Education - Master of Business Administration': ['ED5097', 'ED5880', 'LB5113'],\n",
        "    'Master of Engineering Management': ['EG5200', 'EG5220', 'EG5310'],\n",
        "    'Master of Information Technology': ['CP5046', 'CP5047', 'CP5503'],\n",
        "    'Master of Information Technology - Master of Business Administration': ['CP5046', 'LB5113', 'LB5202'],\n",
        "    'Master of International Tourism and Hospitality Management': ['TO5101', 'TO5103', 'TO5104'],\n",
        "    'Master of International Tourism and Hospitality Management - Master of Business Administration': ['TO5101', 'LB5113', 'LB5202'],\n",
        "    'Master of Professional Accounting': ['CO5117', 'CO5103', 'CO5109'],\n",
        "    'Master of Professional Accounting - Master of Business Administration': ['CO5117', 'CO5103', 'LB5113'],\n",
        "    'Postgraduate Qualifying Program - Business': ['LB5202', 'LB5203', 'LB5212']\n",
        "}\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1753789228629
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the course subjects from the course\n",
        "course_subjects['Bachelor of Information Technology'] # Output: 'CP1401', 'CP1402', 'CP1404']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "['CP1401', 'CP1402', 'CP1404']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1753789228688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dictionary with cleaned course names as keys\n",
        "# For each key-value pair in the original course_subjects dictionary:\n",
        "#   Remove any leading/trailing spaces from the course name (key) using strip()\n",
        "#   Convert the course name to lowercase using lower()\n",
        "#   Keep the value (list of subjects) unchanged\n",
        "cleaned_course_subjects = {k.strip().lower(): v for k, v in course_subjects.items()}\n",
        "cleaned_course_subjects"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "{'bachelor of business': ['BU1002', 'BU1003', 'BU1007'],\n 'bachelor of commerce': ['BU1112', 'BX2011', 'BX2014'],\n 'bachelor of information technology': ['CP1401', 'CP1402', 'CP1404'],\n 'bachelor of tourism, hospitality and events': ['TO1008', 'TO2117', 'TO3052'],\n 'master of business administration': ['LB5113', 'LB5202', 'LB5205'],\n 'master of data science (professional)': ['MA5831', 'MA5840', 'MA5851'],\n 'master of education - master of business administration': ['ED5097',\n  'ED5880',\n  'LB5113'],\n 'master of engineering management': ['EG5200', 'EG5220', 'EG5310'],\n 'master of information technology': ['CP5046', 'CP5047', 'CP5503'],\n 'master of information technology - master of business administration': ['CP5046',\n  'LB5113',\n  'LB5202'],\n 'master of international tourism and hospitality management': ['TO5101',\n  'TO5103',\n  'TO5104'],\n 'master of international tourism and hospitality management - master of business administration': ['TO5101',\n  'LB5113',\n  'LB5202'],\n 'master of professional accounting': ['CO5117', 'CO5103', 'CO5109'],\n 'master of professional accounting - master of business administration': ['CO5117',\n  'CO5103',\n  'LB5113'],\n 'postgraduate qualifying program - business': ['LB5202', 'LB5203', 'LB5212']}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1753789228760
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique course names in DataFrame\n",
        "unique_courses = df['course'].unique()\n",
        "\n",
        "# Find which course names are not keys in cleaned_course_subjects dictionary\n",
        "courses_not_in_cleaned = [course for course in unique_courses if course not in cleaned_course_subjects]\n",
        "courses_not_in_cleaned"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "['master of professional account and master of business administration']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1753789228822
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace invalid course name to a course name in cleaned course subjects dict\n",
        "df['course'].replace('master of professional account and master of business administration', 'master of professional accounting - master of business administration', inplace=True)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1753789228886
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the course value has been updated\n",
        "df['course'].unique()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "array(['master of business administration',\n       'master of education - master of business administration',\n       'master of information technology', 'bachelor of business',\n       'master of engineering management',\n       'bachelor of information technology',\n       'master of professional accounting',\n       'master of international tourism and hospitality management',\n       'bachelor of tourism, hospitality and events',\n       'master of professional accounting - master of business administration',\n       'bachelor of commerce',\n       'master of international tourism and hospitality management - master of business administration',\n       'master of data science (professional)',\n       'master of information technology - master of business administration',\n       'postgraduate qualifying program - business'], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1753789228946
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigns subject codes to each student based on their course.\n",
        "# For each row, looks up the course in the cleaned_course_subjects dictionary.\n",
        "# If the course is found, fills subject_1, subject_2, and subject_3 with the corresponding subject codes.\n",
        "# If the course is not found, fills these columns with None.\n",
        "def assign_subjects(row):\n",
        "    subjects = cleaned_course_subjects.get(row['course'], [None, None, None])\n",
        "    row['subject_1'], row['subject_2'], row['subject_3'] = subjects\n",
        "    return row\n",
        "\n",
        "df = df.apply(assign_subjects, axis=1)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1753789229008
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values in subject 1 to 3\n",
        "df[['subject_1', 'subject_2', 'subject_3']].isnull().sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "subject_1    0\nsubject_2    0\nsubject_3    0\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1753789229068
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['subject_1'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "LB5113    102\nED5097     90\nCP5046     88\nCO5117     79\nBU1002     71\nTO5101     71\nEG5200     69\nCP1401     56\nTO1008     30\nBU1112     22\nMA5831     13\nLB5202      7\nName: subject_1, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1753789229161
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['course'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "master of business administration                                                                 102\nmaster of education - master of business administration                                            90\nmaster of information technology                                                                   77\nbachelor of business                                                                               71\nmaster of engineering management                                                                   69\nbachelor of information technology                                                                 56\nmaster of professional accounting                                                                  55\nmaster of international tourism and hospitality management                                         50\nbachelor of tourism, hospitality and events                                                        30\nmaster of professional accounting - master of business administration                              24\nbachelor of commerce                                                                               22\nmaster of international tourism and hospitality management - master of business administration     21\nmaster of data science (professional)                                                              13\nmaster of information technology - master of business administration                               11\npostgraduate qualifying program - business                                                          7\nName: course, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1753789229236
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create a Course Group Data\n",
        "A new column, Course Group, is created to classify courses into IT and NON-IT categories based on the course names and their content. This categorization helps in segmenting the data for more targeted analysis."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of courses that falls under course group 'IT'\n",
        "it_courses = [ 'master of information technology',\n",
        "    'bachelor of information technology',\n",
        "    'master of data science (professional)',\n",
        "    'master of information technology - master of business administration',\n",
        "] "
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1753789229387
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column 'course_group' based on whether the course is in the IT list\n",
        "df['course_group'] = df['course'].apply(\n",
        "    lambda x: 'IT' if x in it_courses else 'Non-IT'\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1753789229442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['course_group'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "Non-IT    541\nIT        157\nName: course_group, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1753789229567
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Clean Academic Status Data\n",
        "\n",
        "This section establishes student profiles by assigning academic statuses and cohorts. It first designates a fixed number of ‘Excluded’ students within IT and Non-IT groups, then randomly assigns cohorts to others, ensuring specific cohorts only have ‘Satisfactory’ status. Subsequently, remaining academic statuses (‘Satisfactory’, ‘Academic Caution’, and ‘Conditional’) are proportionally allocated between IT and Non-IT students to meet target counts. The process uses controlled randomization to create a realistic and balanced student distribution, finalized with a summary of status counts by course group."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset academic_status\n",
        "df['academic_status'] = None\n",
        "\n",
        "# Step 1: Decide total excluded count and IT excluded count\n",
        "total_excluded = 5\n",
        "excluded_in_it = 3\n",
        "excluded_in_non_it = total_excluded - excluded_in_it  # 2\n",
        "\n",
        "# Step 2: Assign cohorts to all students first (clear student_cohort if needed)\n",
        "df['student_cohort'] = np.nan  # optional clear\n",
        "\n",
        "# Find eligible indices by course_group to assign exclusions\n",
        "it_indices = df[df['course_group'] == 'IT'].index.to_numpy()\n",
        "non_it_indices = df[df['course_group'] == 'Non-IT'].index.to_numpy()\n",
        "\n",
        "# Shuffle indices for randomness\n",
        "np.random.seed(42)\n",
        "it_excluded_indices = np.random.choice(it_indices, size=excluded_in_it, replace=False)\n",
        "non_it_excluded_indices = np.random.choice(non_it_indices, size=excluded_in_non_it, replace=False)\n",
        "\n",
        "# Assign 'Excluded' cohort and status for those selected\n",
        "df.loc[it_excluded_indices, 'student_cohort'] = 'Excluded'\n",
        "df.loc[non_it_excluded_indices, 'student_cohort'] = 'Excluded'\n",
        "\n",
        "# Combine indices using pandas Index union and assign 'Excluded' status\n",
        "excluded_union = pd.Index(it_excluded_indices).union(pd.Index(non_it_excluded_indices))\n",
        "df.loc[excluded_union, 'academic_status'] = 'Excluded'\n",
        "\n",
        "# Step 3: Assign cohorts to the other students (non-excluded)\n",
        "remaining_indices = df.index.difference(excluded_union)\n",
        "valid_cohorts = ['Return to Study', 'First year', 'Transferred', 'Continuing', 'LOA', 'New', 'SRI to JCUB']\n",
        "df.loc[remaining_indices, 'student_cohort'] = np.random.choice(valid_cohorts, size=len(remaining_indices), replace=True)\n",
        "\n",
        "# Step 4: Assign 'Satisfactory' to cohorts which are only allowed 'Satisfactory'\n",
        "satisfactory_only_cohorts = ['SRI to JCUB', 'Transferred', 'New']\n",
        "df.loc[df['student_cohort'].isin(satisfactory_only_cohorts), 'academic_status'] = 'Satisfactory'\n",
        "\n",
        "# Step 5: Define your target counts\n",
        "target_satisfactory = 621\n",
        "target_satisfactory_it = 126\n",
        "target_satisfactory_non_it = 495\n",
        "target_ac = 36\n",
        "target_cond = 36\n",
        "\n",
        "# Step 6: Calculate remaining 'Satisfactory' to assign (excluding already assigned)\n",
        "assigned_satisfactory = df['academic_status'].eq('Satisfactory').sum()\n",
        "remaining_satisfactory = max(target_satisfactory - assigned_satisfactory, 0)\n",
        "\n",
        "# Step 7: Filter remaining unassigned students excluding excluded cohort and satisfactory-only cohorts\n",
        "remaining_mask = (\n",
        "    df['academic_status'].isnull() &\n",
        "    (~df['student_cohort'].isin(satisfactory_only_cohorts + ['Excluded']))\n",
        ")\n",
        "remaining_indices = df[remaining_mask].index\n",
        "\n",
        "# Split remaining_indices by course_group\n",
        "remaining_it_indices = df.loc[remaining_indices][df.loc[remaining_indices, 'course_group'] == 'IT'].index\n",
        "remaining_non_it_indices = df.loc[remaining_indices][df.loc[remaining_indices, 'course_group'] == 'Non-IT'].index\n",
        "\n",
        "# Calculate how many satisfactory assigned already in each course_group\n",
        "assigned_satisfactory_it = df[\n",
        "    (df['academic_status'] == 'Satisfactory') & (df['course_group'] == 'IT')\n",
        "].shape[0]\n",
        "assigned_satisfactory_non_it = df[\n",
        "    (df['academic_status'] == 'Satisfactory') & (df['course_group'] == 'Non-IT')\n",
        "].shape[0]\n",
        "\n",
        "# Remaining satisfactory in each course_group\n",
        "remaining_satisfactory_it = max(target_satisfactory_it - assigned_satisfactory_it, 0)\n",
        "remaining_satisfactory_non_it = max(target_satisfactory_non_it - assigned_satisfactory_non_it, 0)\n",
        "\n",
        "# Proportionally split Academic Caution and Conditional statuses\n",
        "total_remaining_ac_cond = target_ac + target_cond\n",
        "total_remaining_students = len(remaining_it_indices) + len(remaining_non_it_indices)\n",
        "\n",
        "prop_it = len(remaining_it_indices) / total_remaining_students if total_remaining_students > 0 else 0\n",
        "prop_non_it = len(remaining_non_it_indices) / total_remaining_students if total_remaining_students > 0 else 0\n",
        "\n",
        "ac_it = int(round(target_ac * prop_it))\n",
        "ac_non_it = target_ac - ac_it\n",
        "\n",
        "cond_it = int(round(target_cond * prop_it))\n",
        "cond_non_it = target_cond - cond_it\n",
        "\n",
        "# Build status lists\n",
        "status_it = (\n",
        "    ['Satisfactory'] * remaining_satisfactory_it +\n",
        "    ['Academic Caution'] * ac_it +\n",
        "    ['Conditional'] * cond_it\n",
        ")\n",
        "\n",
        "status_non_it = (\n",
        "    ['Satisfactory'] * remaining_satisfactory_non_it +\n",
        "    ['Academic Caution'] * ac_non_it +\n",
        "    ['Conditional'] * cond_non_it\n",
        ")\n",
        "\n",
        "# Function to adjust length (padding/truncation)\n",
        "def adjust_length(lst, desired_len, filler):\n",
        "    if len(lst) > desired_len:\n",
        "        return lst[:desired_len]\n",
        "    elif len(lst) < desired_len:\n",
        "        return lst + [filler] * (desired_len - len(lst))\n",
        "    else:\n",
        "        return lst\n",
        "\n",
        "status_it = adjust_length(status_it, len(remaining_it_indices), 'Academic Caution')\n",
        "status_non_it = adjust_length(status_non_it, len(remaining_non_it_indices), 'Academic Caution')\n",
        "\n",
        "# Shuffle status lists\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(status_it)\n",
        "np.random.shuffle(status_non_it)\n",
        "\n",
        "# Assign statuses back\n",
        "df.loc[remaining_it_indices, 'academic_status'] = status_it\n",
        "df.loc[remaining_non_it_indices, 'academic_status'] = status_non_it\n",
        "\n",
        "# Final checks\n",
        "#Group by course_group and academic_status and count\n",
        "status_distribution = df.groupby(['course_group', 'academic_status']).size().unstack(fill_value=0)\n",
        "\n",
        "print(\"Academic status distribution by course_group:\\n\")\n",
        "print(status_distribution)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Academic status distribution by course_group:\n\nacademic_status  Academic Caution  Conditional  Excluded  Satisfactory\ncourse_group                                                          \nIT                             21            7         3           126\nNon-IT                         29           15         2           495\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1753789229655
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Clean the student cohort column"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['student_cohort'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "New                109\nReturn to Study    107\nSRI to JCUB        104\nTransferred        102\nLOA                 99\nFirst year          92\nContinuing          80\nExcluded             5\nName: student_cohort, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1753789229836
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Clean Failed Subjects Data\n",
        "This section assigns values to the failed_subjects column by grouping students based on academic status and course group (IT or Non-IT). It sets high failure counts for excluded students and supplements with random selections to meet specific quotas. Most satisfactory students are assigned zero failures, with a few outliers receiving 1 or 2 failed subjects. Remaining students receive mostly 1 or 2 failed subjects, with some zero-value outliers for variation. The process ensures controlled, reproducible, and realistic failure data distributions across groups, finalized with a summary of assigned values."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['failed_subjects'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "CP5639    8\nCP5633    7\nCP1401    5\nCP1404    5\nCP1407    3\nCP1406    2\nCP5046    2\nCP5047    1\nName: failed_subjects, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1753789229898
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Masks for clarity\n",
        "mask_satisfactory_it = (df['academic_status'] == 'Satisfactory') & (df['course_group'] == 'IT')\n",
        "mask_it = (df['course_group'] == 'IT')\n",
        "\n",
        "mask_satisfactory_non_it = (df['academic_status'] == 'Satisfactory') & (df['course_group'] == 'Non-IT')\n",
        "mask_non_it = (df['course_group'] == 'Non-IT')\n",
        "\n",
        "mask_excluded = (df['academic_status'] == 'Excluded')\n",
        "\n",
        "# Excluded indices\n",
        "excluded_it_indices = df[mask_excluded & mask_it].index\n",
        "excluded_non_it_indices = df[mask_excluded & mask_non_it].index\n",
        "\n",
        "# ---- Assign failed_subjects > 3 ----\n",
        "\n",
        "# IT group\n",
        "num_it_excluded = len(excluded_it_indices)\n",
        "num_it_failed_gt3 = 10\n",
        "num_it_remaining_gt3 = num_it_failed_gt3 - num_it_excluded\n",
        "\n",
        "if num_it_remaining_gt3 < 0:\n",
        "    raise ValueError(f\"IT Excluded students ({num_it_excluded}) exceed 10 total failed_subjects>3 limit.\")\n",
        "\n",
        "eligible_it_indices = df[mask_it & ~mask_excluded].index\n",
        "np.random.seed(42)\n",
        "it_gt3_extra = np.random.choice(eligible_it_indices, size=num_it_remaining_gt3, replace=False)\n",
        "df.loc[excluded_it_indices.union(it_gt3_extra), 'failed_subjects'] = 4\n",
        "\n",
        "# Non-IT group\n",
        "num_non_it_excluded = len(excluded_non_it_indices)\n",
        "num_non_it_failed_gt3 = 7\n",
        "num_non_it_remaining_gt3 = num_non_it_failed_gt3 - num_non_it_excluded\n",
        "\n",
        "if num_non_it_remaining_gt3 < 0:\n",
        "    raise ValueError(f\"Non-IT Excluded students ({num_non_it_excluded}) exceed 7 total failed_subjects>3 limit.\")\n",
        "\n",
        "eligible_non_it_indices = df[mask_non_it & ~mask_excluded].index\n",
        "non_it_gt3_extra = np.random.choice(eligible_non_it_indices, size=num_non_it_remaining_gt3, replace=False)\n",
        "df.loc[excluded_non_it_indices.union(non_it_gt3_extra), 'failed_subjects'] = 4\n",
        "\n",
        "# ---- IT Satisfactory: assign failed_subjects = 0 to most, leave 2-3 outliers with 1 or 2 ----\n",
        "\n",
        "satisfactory_it_indices = df[mask_satisfactory_it].index\n",
        "num_outliers_it_satisfactory = 6\n",
        "\n",
        "np.random.seed(101)\n",
        "outliers_it_satisfactory = np.random.choice(satisfactory_it_indices, size=num_outliers_it_satisfactory, replace=False)\n",
        "df.loc[satisfactory_it_indices.difference(outliers_it_satisfactory), 'failed_subjects'] = 0\n",
        "df.loc[outliers_it_satisfactory, 'failed_subjects'] = np.random.choice([1, 2], size=num_outliers_it_satisfactory)\n",
        "\n",
        "# ---- IT remaining students (excluding assigned above) assign failed_subjects 1 or 2 with 2-3 zeros as outliers ----\n",
        "\n",
        "assigned_it_failed = df.loc[mask_it, 'failed_subjects'].notna()\n",
        "remaining_it = df[mask_it & ~assigned_it_failed].index\n",
        "num_zeros_it_remaining = 3\n",
        "\n",
        "np.random.seed(102)\n",
        "sample_size_it = min(num_zeros_it_remaining, len(remaining_it))\n",
        "if sample_size_it > 0:\n",
        "    zeros_it_remaining = np.random.choice(remaining_it, size=sample_size_it, replace=False)\n",
        "    df.loc[zeros_it_remaining, 'failed_subjects'] = 0\n",
        "\n",
        "    remaining_it_other = remaining_it.difference(zeros_it_remaining)\n",
        "    if len(remaining_it_other) > 0:\n",
        "        df.loc[remaining_it_other, 'failed_subjects'] = np.random.choice([1, 2], size=len(remaining_it_other), replace=True)\n",
        "else:\n",
        "    # If no remaining IT to sample zeros, assign 1 or 2 to all remaining (if any)\n",
        "    if len(remaining_it) > 0:\n",
        "        df.loc[remaining_it, 'failed_subjects'] = np.random.choice([1, 2], size=len(remaining_it), replace=True)\n",
        "\n",
        "# ---- Non-IT Satisfactory: assign failed_subjects = 0 to most, leave 2-3 outliers with 1 or 2 ----\n",
        "\n",
        "satisfactory_non_it_indices = df[mask_satisfactory_non_it].index\n",
        "num_outliers_non_it_satisfactory = 3\n",
        "\n",
        "np.random.seed(103)\n",
        "outliers_non_it_satisfactory = np.random.choice(satisfactory_non_it_indices, size=num_outliers_non_it_satisfactory, replace=False)\n",
        "df.loc[satisfactory_non_it_indices.difference(outliers_non_it_satisfactory), 'failed_subjects'] = 0\n",
        "df.loc[outliers_non_it_satisfactory, 'failed_subjects'] = np.random.choice([1, 2], size=num_outliers_non_it_satisfactory)\n",
        "\n",
        "# ---- Non-IT remaining students (excluding assigned above) assign failed_subjects 1 or 2 with 2-3 zeros as outliers ----\n",
        "\n",
        "assigned_non_it_failed = df.loc[mask_non_it, 'failed_subjects'].notna()\n",
        "remaining_non_it = df[mask_non_it & ~assigned_non_it_failed].index\n",
        "num_zeros_non_it_remaining = 3\n",
        "\n",
        "np.random.seed(104)\n",
        "sample_size_non_it = min(num_zeros_non_it_remaining, len(remaining_non_it))\n",
        "if sample_size_non_it > 0:\n",
        "    zeros_non_it_remaining = np.random.choice(remaining_non_it, size=sample_size_non_it, replace=False)\n",
        "    df.loc[zeros_non_it_remaining, 'failed_subjects'] = 0\n",
        "\n",
        "    remaining_non_it_other = remaining_non_it.difference(zeros_non_it_remaining)\n",
        "    if len(remaining_non_it_other) > 0:\n",
        "        df.loc[remaining_non_it_other, 'failed_subjects'] = np.random.choice([1, 2], size=len(remaining_non_it_other), replace=True)\n",
        "else:\n",
        "    # If no remaining Non-IT to sample zeros, assign 1 or 2 to all remaining (if any)\n",
        "    if len(remaining_non_it) > 0:\n",
        "        df.loc[remaining_non_it, 'failed_subjects'] = np.random.choice([1, 2], size=len(remaining_non_it), replace=True)\n",
        "\n",
        "# ---- Convert 'failed_subjects' to numeric and clean to avoid type errors ----\n",
        "\n",
        "df['failed_subjects'] = pd.to_numeric(df['failed_subjects'], errors='coerce')   # convert with coercion\n",
        "df['failed_subjects'].fillna(0, inplace=True)                                  # fill NaNs with zero\n",
        "df['failed_subjects'] = df['failed_subjects'].astype(int)                      # convert to int\n",
        "\n",
        "# ---- Summary ----\n",
        "\n",
        "print(f\"Total students with failed_subjects > 3: {(df['failed_subjects'] > 3).sum()}\")\n",
        "print(f\" - IT failed_subjects > 3: {df[(df['course_group'] == 'IT') & (df['failed_subjects'] > 3)].shape[0]}\")\n",
        "print(f\" - Non-IT failed_subjects > 3: {df[(df['course_group'] == 'Non-IT') & (df['failed_subjects'] > 3)].shape[0]}\")\n",
        "\n",
        "print(f\"IT Satisfactory students with failed_subjects = 0: {(df[mask_satisfactory_it & (df['failed_subjects'] == 0)]).shape[0]}\")\n",
        "print(f\"IT Satisfactory outliers with failed_subjects 1 or 2: {(df[mask_satisfactory_it & (df['failed_subjects'] > 0)]).shape[0]}\")\n",
        "\n",
        "print(f\"Non-IT Satisfactory students with failed_subjects = 0: {(df[mask_satisfactory_non_it & (df['failed_subjects'] == 0)]).shape[0]}\")\n",
        "print(f\"Non-IT Satisfactory outliers with failed_subjects 1 or 2: {(df[mask_satisfactory_non_it & (df['failed_subjects'] > 0)]).shape[0]}\")\n",
        "\n",
        "print(f\"Failed subjects distribution for IT students:\\n{df[mask_it]['failed_subjects'].value_counts()}\")\n",
        "print(f\"Failed subjects distribution for Non-IT students:\\n{df[mask_non_it]['failed_subjects'].value_counts()}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total students with failed_subjects > 3: 8\n - IT failed_subjects > 3: 6\n - Non-IT failed_subjects > 3: 2\nIT Satisfactory students with failed_subjects = 0: 120\nIT Satisfactory outliers with failed_subjects 1 or 2: 6\nNon-IT Satisfactory students with failed_subjects = 0: 492\nNon-IT Satisfactory outliers with failed_subjects 1 or 2: 3\nFailed subjects distribution for IT students:\n0    126\n2     14\n1     11\n4      6\nName: failed_subjects, dtype: int64\nFailed subjects distribution for Non-IT students:\n0    495\n1     22\n2     22\n4      2\nName: failed_subjects, dtype: int64\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1753789229990
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Clean Attendance Data\n",
        "\n",
        "This section generates attendance percentages for three subjects based on each student’s academic status, cohort classification, and number of failed subjects. Attendance averages are adjusted to reflect realistic behavioral patterns: students with satisfactory academic standing typically exhibit higher attendance rates, whereas those identified as at risk or excluded show lower rates. Additionally, attendance is modulated according to student cohort, with new or returning students generally having reduced attendance compared to continuing students. Attendance values are sampled from normal distributions with these tailored parameters and clipped to remain within the 0-100% range. A fixed random seed ensures replicability of the results. Summary statistics provide insight into average attendance both overall and segmented by academic status and cohort group."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Minimum and Maximum attendance threshold\n",
        "MIN_ATTD_ASSIGN = 0\n",
        "MAX_ATTD_ASSIGN = 100\n",
        "\n",
        "def generate_attendance(row):\n",
        "    \"\"\"\n",
        "    Generate realistic attendance for three subjects based on academic status, cohort, and failed_subjects.\n",
        "    \"\"\"\n",
        "    base_mean = 66.5 # global research value for mean attendance\n",
        "    base_std = 13\n",
        "\n",
        "    # Academic status logic\n",
        "    status = row['academic_status']\n",
        "    if status == 'Satisfactory':\n",
        "        mean = base_mean + 3\n",
        "        std = 7\n",
        "    elif status in ['Academic Caution', 'Conditional']:\n",
        "        mean = base_mean - 6\n",
        "        std = 13\n",
        "    elif status in ['At Risk', 'Excluded']:\n",
        "        mean = base_mean - 14\n",
        "        std = 17\n",
        "    else:\n",
        "        mean = base_mean\n",
        "        std = base_std\n",
        "\n",
        "    # Cohort adjustment\n",
        "    cohort = row['student_cohort'] if isinstance(row['student_cohort'], str) else ''\n",
        "    if 'First year' in cohort or 'New' in cohort:\n",
        "        mean -= 7\n",
        "    elif 'Return' in cohort or 'Transferred' in cohort:\n",
        "        mean -= 3\n",
        "    elif 'Continuing' in cohort or 'LOA' in cohort:\n",
        "        mean -= 1\n",
        "\n",
        "    # Adjust for number of failed_subjects (robust to missing/NaN)\n",
        "    try:\n",
        "        fails = int(row.get('failed_subjects', 0))\n",
        "    except:\n",
        "        fails = 0\n",
        "    if fails > 3:\n",
        "        mean -= 12\n",
        "    elif fails == 0 and status == 'Satisfactory':\n",
        "        mean += 4  # these are your most regular attenders!\n",
        "\n",
        "    # Clamp all means within sensible range\n",
        "    mean = max(MIN_ATTD_ASSIGN, min(MAX_ATTD_ASSIGN, mean))\n",
        "    std = min(std, 20)  # don't let stdev go excessive\n",
        "\n",
        "    # Generate attendance for 3 subjects with some random variation\n",
        "    att1 = np.clip(np.random.normal(loc=mean, scale=std), MIN_ATTD_ASSIGN, MAX_ATTD_ASSIGN)\n",
        "    att2 = np.clip(np.random.normal(loc=mean + np.random.uniform(-3,3), scale=std), MIN_ATTD_ASSIGN, MAX_ATTD_ASSIGN)\n",
        "    att3 = np.clip(np.random.normal(loc=mean + np.random.uniform(-3,3), scale=std), MIN_ATTD_ASSIGN, MAX_ATTD_ASSIGN)\n",
        "\n",
        "    return pd.Series([round(att1,1), round(att2,1), round(att3,1)])\n",
        "\n",
        "# ---- APPLY TO THE DATAFRAME ----\n",
        "\n",
        "np.random.seed(101)  # for reproducible results\n",
        "\n",
        "df[['attendance_1', 'attendance_2', 'attendance_3']] = df.apply(generate_attendance, axis=1)\n",
        "\n",
        "# ---- CHECK THE RESULTING MEANS ----\n",
        "\n",
        "print(\"Mean attendance_1:\", df['attendance_1'].mean())\n",
        "print(\"Mean attendance_2:\", df['attendance_2'].mean())\n",
        "print(\"Mean attendance_3:\", df['attendance_3'].mean())\n",
        "\n",
        "# Combined overall mean:\n",
        "overall_attendance_mean = pd.concat([df['attendance_1'],df['attendance_2'],df['attendance_3']]).mean()\n",
        "print(\"Overall attendance mean (all columns):\", overall_attendance_mean)\n",
        "\n",
        "# To see attendance distribution by academic status or cohort:\n",
        "print(\"\\nAttendance by Academic Status:\\n\", df.groupby('academic_status')[['attendance_1','attendance_2','attendance_3']].mean())\n",
        "print(\"\\nAttendance by Student Cohort:\\n\", df.groupby('student_cohort')[['attendance_1','attendance_2','attendance_3']].mean())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Mean attendance_1: 68.93209169054441\nMean attendance_2: 68.54656160458453\nMean attendance_3: 68.56389684813755\nOverall attendance mean (all columns): 68.6808500477555\n\nAttendance by Academic Status:\n                   attendance_1  attendance_2  attendance_3\nacademic_status                                           \nAcademic Caution     56.896000     54.612000     55.014000\nConditional          61.513636     57.818182     58.213636\nExcluded             48.760000     33.340000     44.720000\nSatisfactory         70.326409     70.332045     70.213527\n\nAttendance by Student Cohort:\n                  attendance_1  attendance_2  attendance_3\nstudent_cohort                                           \nContinuing          69.946250     70.867500     70.945000\nExcluded            48.760000     33.340000     44.720000\nFirst year          64.881522     63.025000     63.453261\nLOA                 71.006061     71.032323     71.539394\nNew                 66.857798     66.870642     66.572477\nReturn to Study     68.513084     66.987850     65.785047\nSRI to JCUB         73.162500     72.908654     73.074038\nTransferred         69.108824     69.998039     70.031373\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1753789230081
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Clean Subject Assessments Score\n",
        "\n",
        "This section assigns realistic assessment scores to each student, with adjustments based on academic status, cohort membership, and attendance patterns, resulting in higher scores for students with stronger academic performance. Subsequently, a small proportion of students (approximately 5%) are randomly selected as outliers and assigned notably low or high scores to introduce additional variability reflecting real-world data distributions. The code also tracks and summarizes the frequency of students appearing as outliers across multiple assessments."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subject_cols = [f\"subject_{i}_assess_{j}\" for i in range(1,4) for j in range(1,4)]\n",
        "print(df[subject_cols].describe().transpose())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "                    count       mean        std   min      25%     50%  \\\nsubject_1_assess_1  698.0  51.630702  28.580143  0.15  27.8150  52.105   \nsubject_1_assess_2  698.0  49.795143  29.158082  0.01  22.6075  49.780   \nsubject_1_assess_3  698.0  49.373854  29.734640  0.09  23.3275  47.630   \nsubject_2_assess_1  698.0  52.323109  28.602609  0.16  27.7725  53.340   \nsubject_2_assess_2  698.0  47.862307  29.092952  0.30  22.5225  46.940   \nsubject_2_assess_3  698.0  49.632564  28.842227  0.04  25.1425  50.740   \nsubject_3_assess_1  698.0  50.648266  29.296110  0.12  24.2625  52.440   \nsubject_3_assess_2  698.0  48.930129  27.774693  0.19  25.3175  46.675   \nsubject_3_assess_3  698.0  48.603209  28.930261  0.31  25.7075  48.550   \n\n                        75%    max  \nsubject_1_assess_1  75.6475  99.98  \nsubject_1_assess_2  75.5650  99.92  \nsubject_1_assess_3  76.1800  99.68  \nsubject_2_assess_1  77.5200  99.91  \nsubject_2_assess_2  72.9775  99.87  \nsubject_2_assess_3  73.5000  99.99  \nsubject_3_assess_1  76.3475  99.89  \nsubject_3_assess_2  71.3025  99.71  \nsubject_3_assess_3  73.6050  99.91  \n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1753789230150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define subject assessment columns\n",
        "subject_cols = [f\"subject_{i}_assess_{j}\"\n",
        "                for i in range(1, 4)  # subjects 1 to 3\n",
        "                for j in range(1, 5)]  # assessments 1 to 4\n",
        "\n",
        "def assign_assessments(row):\n",
        "    # Step 1: Immediate 0s for Excluded\n",
        "    if row['academic_status'] == 'Excluded':\n",
        "        return pd.Series([0] * len(subject_cols), index=subject_cols)\n",
        "\n",
        "    # 2. Set base mean & std by prior academic_status\n",
        "    status = row['academic_status']\n",
        "    base = {\n",
        "        'Satisfactory':     (72, 7),\n",
        "        'Academic Caution': (61, 12),\n",
        "        'Conditional':      (58, 13),\n",
        "        'At Risk':          (52, 16)\n",
        "    }\n",
        "    mean, std = base.get(status, (60, 12))\n",
        "\n",
        "    # Cohort adjustments\n",
        "    cohort = str(row['student_cohort'])\n",
        "    if 'First year' in cohort or 'New' in cohort:\n",
        "        mean -= 4\n",
        "    elif 'Return' in cohort or 'Transferred' in cohort:\n",
        "        mean -= 2\n",
        "\n",
        "    # Attendance adjustment: stronger for very low, weaker for medium/high\n",
        "    attendance_cols = ['attendance_1','attendance_2','attendance_3']\n",
        "    if set(attendance_cols) <= set(row.index):\n",
        "        att = float(np.mean([row[col] for col in attendance_cols]))\n",
        "        if att >= 80:\n",
        "            mean += 2\n",
        "        elif att < 60:\n",
        "            mean -= 3\n",
        "        elif att < 50:\n",
        "            mean -= 6\n",
        "        # else no adjustment\n",
        "    # Clamp mean within 40-95\n",
        "    mean = max(40, min(95, mean))\n",
        "    std = min(std, 20)\n",
        "\n",
        "    # Generate marks for each assessment (simulate real small ups and downs per assessment)\n",
        "    scores = []\n",
        "    for _ in subject_cols:\n",
        "        score = np.random.normal(loc=mean + np.random.uniform(-2,2), scale=std)\n",
        "        score = max(0, min(100, round(score, 1)))\n",
        "        scores.append(score)\n",
        "    return pd.Series(scores, index=subject_cols)\n",
        "\n",
        "# Apply to a df\n",
        "np.random.seed(120)  # For reproducibility\n",
        "df[subject_cols] = df.apply(assign_assessments, axis=1)\n",
        "\n",
        "# Quick check\n",
        "print(df[subject_cols].mean().mean())   # Should be mid 60s, or to your liking\n",
        "print(df.groupby('academic_status')[subject_cols].mean().mean(axis=1))  # Means per status\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "68.37304202483286\nacademic_status\nAcademic Caution    56.682833\nConditional         54.615152\nExcluded             0.000000\nSatisfactory        70.352187\ndtype: float64\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1753789230487
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subject_cols = [f\"subject_{i}_assess_{j}\" for i in range(1,4) for j in range(1,4)]\n",
        "print(df[subject_cols].describe().transpose())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "                    count       mean        std  min     25%    50%     75%  \\\nsubject_1_assess_1  698.0  68.596562  11.108105  0.0  64.000  69.30  74.875   \nsubject_1_assess_2  698.0  68.651719  10.502881  0.0  64.100  69.40  74.700   \nsubject_1_assess_3  698.0  68.923782  10.390920  0.0  64.925  69.80  75.000   \nsubject_2_assess_1  698.0  68.487536  10.874676  0.0  63.900  69.80  74.900   \nsubject_2_assess_2  698.0  68.485817  10.775075  0.0  64.025  69.70  74.800   \nsubject_2_assess_3  698.0  67.929799  10.958035  0.0  63.225  69.15  74.600   \nsubject_3_assess_1  698.0  68.312034  10.769822  0.0  63.500  69.60  74.700   \nsubject_3_assess_2  698.0  67.912034  10.702801  0.0  63.325  68.80  74.575   \nsubject_3_assess_3  698.0  68.145415  10.917010  0.0  63.500  69.40  74.275   \n\n                     max  \nsubject_1_assess_1  93.9  \nsubject_1_assess_2  91.0  \nsubject_1_assess_3  94.5  \nsubject_2_assess_1  93.0  \nsubject_2_assess_2  90.0  \nsubject_2_assess_3  90.0  \nsubject_3_assess_1  94.6  \nsubject_3_assess_2  87.7  \nsubject_3_assess_3  91.3  \n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1753789230549
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_outliers(\n",
        "    df,\n",
        "    subject_cols,\n",
        "    low_pct=0.05,\n",
        "    high_pct=0.05,\n",
        "    filter_academic_status=None,  # e.g. ['Satisfactory', 'At Risk'], None means all\n",
        "    filter_cohorts=None           # e.g. ['First year', 'New'], None means all\n",
        "):\n",
        "\n",
        "    np.random.seed(999)  # For reproducibility\n",
        "\n",
        "    # Filter rows\n",
        "    if filter_academic_status is not None:\n",
        "        mask_status = df['academic_status'].isin(filter_academic_status)\n",
        "    else:\n",
        "        mask_status = pd.Series(True, index=df.index)\n",
        "\n",
        "    if filter_cohorts is not None:\n",
        "        mask_cohort = df['student_cohort'].isin(filter_cohorts)\n",
        "    else:\n",
        "        mask_cohort = pd.Series(True, index=df.index)\n",
        "\n",
        "    eligible_indices = df[mask_status & mask_cohort].index.tolist()\n",
        "    n_students = len(eligible_indices)\n",
        "\n",
        "    if n_students == 0:\n",
        "        print(\"Warning: No students matching the filter criteria for outliers.\")\n",
        "        return df, {}\n",
        "\n",
        "    outliers_log = {'low_outliers': {}, 'high_outliers': {}}\n",
        "\n",
        "    for col in subject_cols:\n",
        "        n_low = int(n_students * low_pct)\n",
        "        n_high = int(n_students * high_pct)\n",
        "\n",
        "        # Select random students for low outliers\n",
        "        low_indices = np.random.choice(eligible_indices, size=n_low, replace=False)\n",
        "        # Ensure no overlap\n",
        "        remaining_for_high = list(set(eligible_indices) - set(low_indices))\n",
        "        n_high = min(n_high, len(remaining_for_high))\n",
        "        high_indices = np.random.choice(remaining_for_high, size=n_high, replace=False)\n",
        "\n",
        "        # Assign low scores (uniform 0 to 40)\n",
        "        low_scores = np.random.uniform(0, 40, size=n_low).round(1)\n",
        "        df.loc[low_indices, col] = low_scores\n",
        "\n",
        "        # Assign high scores (uniform 90 to 100)\n",
        "        high_scores = np.random.uniform(90, 100, size=n_high).round(1)\n",
        "        df.loc[high_indices, col] = high_scores\n",
        "\n",
        "        # Log info\n",
        "        outliers_log['low_outliers'][col] = list(low_indices)\n",
        "        outliers_log['high_outliers'][col] = list(high_indices)\n",
        "\n",
        "        print(f\"{col}: assigned {n_low} low outliers, {n_high} high outliers\")\n",
        "\n",
        "    return df, outliers_log\n",
        "\n",
        "# List of assessment columns\n",
        "subject_cols = [col for col in df.columns if col.startswith('subject_') and 'assess_' in col]\n",
        "\n",
        "# Add outliers only for Satisfactory students\n",
        "df, log = add_outliers(\n",
        "    df,\n",
        "    subject_cols,\n",
        "    low_pct=0.05,\n",
        "    high_pct=0.05,\n",
        "    filter_academic_status=['Satisfactory'],\n",
        "    filter_cohorts=None  # Or specify cohorts like ['First year','New']\n",
        ")\n",
        "\n",
        "# Check summary of affected rows\n",
        "total_low_outliers = sum(len(v) for v in log['low_outliers'].values())\n",
        "total_high_outliers = sum(len(v) for v in log['high_outliers'].values())\n",
        "\n",
        "print(f\"Total low outliers assigned: {total_low_outliers}\")\n",
        "print(f\"Total high outliers assigned: {total_high_outliers}\")\n",
        "subject_cols = [f\"subject_{i}_assess_{j}\"\n",
        "                for i in range(1, 4)  # subjects 1 to 3\n",
        "                for j in range(1, 5)]  # assessments 1 to 4"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "subject_1_assess_1: assigned 31 low outliers, 31 high outliers\nsubject_1_assess_2: assigned 31 low outliers, 31 high outliers\nsubject_1_assess_3: assigned 31 low outliers, 31 high outliers\nsubject_1_assess_4: assigned 31 low outliers, 31 high outliers\nsubject_2_assess_1: assigned 31 low outliers, 31 high outliers\nsubject_2_assess_2: assigned 31 low outliers, 31 high outliers\nsubject_2_assess_3: assigned 31 low outliers, 31 high outliers\nsubject_2_assess_4: assigned 31 low outliers, 31 high outliers\nsubject_3_assess_1: assigned 31 low outliers, 31 high outliers\nsubject_3_assess_2: assigned 31 low outliers, 31 high outliers\nsubject_3_assess_3: assigned 31 low outliers, 31 high outliers\nsubject_3_assess_4: assigned 31 low outliers, 31 high outliers\nTotal low outliers assigned: 372\nTotal high outliers assigned: 372\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1753789230631
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build dictionaries: column -> set(row indices)\n",
        "low_outlier_indices = {}\n",
        "high_outlier_indices = {}\n",
        "\n",
        "for col in subject_cols:\n",
        "    low_outlier_indices[col] = set(df[df[col] <= 40].index)\n",
        "    high_outlier_indices[col] = set(df[df[col] >= 90].index)\n"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1753789230712
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# For low outliers:\n",
        "all_low_indices = [idx for indices in low_outlier_indices.values() for idx in indices]\n",
        "low_counts = Counter(all_low_indices)\n",
        "\n",
        "# For high outliers:\n",
        "all_high_indices = [idx for indices in high_outlier_indices.values() for idx in indices]\n",
        "high_counts = Counter(all_high_indices)\n"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1753789230767
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many students are outliers in 1, 2, ... n columns?\n",
        "print(\"Low outliers per student frequency:\")\n",
        "print(Counter(low_counts.values()))\n",
        "print(\"\\nHigh outliers per student frequency:\")\n",
        "print(Counter(high_counts.values()))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Low outliers per student frequency:\nCounter({1: 242, 2: 81, 3: 16, 12: 5, 5: 2})\n\nHigh outliers per student frequency:\nCounter({1: 213, 2: 66, 3: 21})\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1753789230826
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subject_cols = [f\"subject_{i}_assess_{j}\" for i in range(1,4) for j in range(1,4)]\n",
        "print(df[subject_cols].describe().transpose())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "                    count       mean        std  min     25%    50%   75%  \\\nsubject_1_assess_1  698.0  67.490258  16.241099  0.0  63.500  69.10  75.6   \nsubject_1_assess_2  698.0  67.503438  15.824780  0.0  63.500  69.35  75.3   \nsubject_1_assess_3  698.0  67.696848  15.796821  0.0  64.200  69.70  75.5   \nsubject_2_assess_1  698.0  67.281519  16.035016  0.0  63.200  69.80  75.5   \nsubject_2_assess_2  698.0  67.342120  15.709418  0.0  63.325  69.65  75.4   \nsubject_2_assess_3  698.0  66.614327  16.378063  0.0  62.200  69.05  74.9   \nsubject_3_assess_1  698.0  67.162464  15.978574  0.0  62.600  69.50  75.4   \nsubject_3_assess_2  698.0  66.772350  15.833371  0.0  62.400  68.70  75.0   \nsubject_3_assess_3  698.0  66.993983  16.025965  0.0  62.400  69.30  74.9   \n\n                     max  \nsubject_1_assess_1  99.9  \nsubject_1_assess_2  99.8  \nsubject_1_assess_3  99.7  \nsubject_2_assess_1  99.6  \nsubject_2_assess_2  99.4  \nsubject_2_assess_3  99.5  \nsubject_3_assess_1  99.9  \nsubject_3_assess_2  99.3  \nsubject_3_assess_3  99.7  \n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1753789230880
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Clean Identified Issues\n",
        "\n",
        "In this section, the identified_issues column is cleaned and adjusted to simulate realistic student challenges. Issue names are standardized using a mapping dictionary for consistency. For students with a \"Satisfactory\" academic status, those in the \"New\" or \"First Year\" cohort have a 25% chance of being assigned \"Late Enrollment\", while others are mostly assigned \"No Issue Reported\". For other satisfactory students, a small proportion are randomly assigned 1–2 realistic issues, while existing issues are retained or cleared based on probability. Non-satisfactory students generally keep their reported issues, with a few cases cleared to simulate variability. The final output includes validation checks on issue distribution across cohorts and academic statuses."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['identified_issues'].unique()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "array(['Late Enrollment', 'Poor time management', 'Death in family',\n       'Sickness', 'Mental health'], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1753789230950
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate p_clear\n",
        "n_non_satisf_with_issues = df[\n",
        "    (df['academic_status'].str.strip().str.lower() != 'satisfactory') &\n",
        "    (df['identified_issues'] != 'No Issue Reported')\n",
        "].shape[0]\n",
        "\n",
        "desired_to_clear = 4  # e.g., clear 4 students\n",
        "p_clear = desired_to_clear / n_non_satisf_with_issues if n_non_satisf_with_issues > 0 else 0\n"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1753789231028
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping dictionary to standardize issue names\n",
        "issue_map = {\n",
        "    \"poor time management\": \"Poor Time Management\",\n",
        "    \"late enrollment\": \"Late Enrollment\",\n",
        "    \"death in family\": \"Death in Family\",\n",
        "    \"mental health\": \"Mental Health\",\n",
        "    \"sickness\": \"Sickness\",\n",
        "    \"attendance\": \"Attendance\",\n",
        "    \"non submission\": \"Non Submission\",\n",
        "    \"concern for welfare\": \"Concern for Welfare\",\n",
        "}\n",
        "\n",
        "def clean_issues(cell):\n",
        "    if pd.isnull(cell) or str(cell).strip().lower() in ['', 'none', '-']:\n",
        "        return \"No Issue Reported\"\n",
        "    # Normalize delimiters and split multiple issues\n",
        "    issues = str(cell).replace(',', ';').split(';')\n",
        "    cleaned = [issue_map.get(i.strip().lower(), i.strip().title()) for i in issues if i.strip()]\n",
        "    unique_issues = sorted(set(cleaned))\n",
        "    return '; '.join(unique_issues)\n",
        "\n",
        "# Clean the existing column\n",
        "df['identified_issues'] = df['identified_issues'].apply(clean_issues)\n",
        "\n",
        "# Known issues for random assignment, excluding \"No Issue Reported\"\n",
        "known_issues_list = list(issue_map.values())\n",
        "\n",
        "# Seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "def assign_realistic_issues(row):\n",
        "    academic_status = str(row['academic_status']).strip().lower()\n",
        "    cohort = str(row['student_cohort']).strip().lower()\n",
        "    current_issues = row['identified_issues']\n",
        "\n",
        "    if academic_status == 'satisfactory':\n",
        "        if cohort in ['new', 'first year']:\n",
        "            # 25% get \"Late Enrollment\", else \"No Issue Reported\"\n",
        "            if np.random.rand() < 0.25:\n",
        "                return \"Late Enrollment\"\n",
        "            else:\n",
        "                return \"No Issue Reported\"\n",
        "        else:\n",
        "            # Other satisfactory students: 10% random issues outliers\n",
        "            if current_issues == \"No Issue Reported\":\n",
        "                if np.random.rand() < 0.10:\n",
        "                    # Randomly assign 1-2 issues for realism\n",
        "                    num_issues = np.random.choice([1, 2], p=[0.7, 0.3])\n",
        "                    chosen_issues = np.random.choice(known_issues_list, size=num_issues, replace=False)\n",
        "                    return '; '.join(sorted(chosen_issues))\n",
        "                else:\n",
        "                    return \"No Issue Reported\"\n",
        "            else:\n",
        "                # Already has issue(s), retain with 90% probability or clear with 10% (simulate some data noise)\n",
        "                if np.random.rand() < 0.90:\n",
        "                    return current_issues\n",
        "                else:\n",
        "                    return \"No Issue Reported\"\n",
        "    else:\n",
        "        # For Non-Satisfactory students:\n",
        "        if current_issues == \"No Issue Reported\":\n",
        "            return current_issues\n",
        "        else:\n",
        "            if np.random.rand() < p_clear:\n",
        "                return \"No Issue Reported\"\n",
        "            else:\n",
        "                return current_issues\n",
        "\n",
        "# Apply adjustment\n",
        "df['identified_issues'] = df.apply(assign_realistic_issues, axis=1)\n",
        "\n",
        "# Validate distribution, example printout:\n",
        "print(df.groupby(['student_cohort', 'academic_status', 'identified_issues']).size())\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "student_cohort  academic_status   identified_issues   \nContinuing      Academic Caution  Mental Health            1\n                                  Poor Time Management     2\n                                  Sickness                 1\n                Conditional       Late Enrollment          1\n                                  Mental Health            3\n                                                          ..\nTransferred     Satisfactory      Late Enrollment         17\n                                  Mental Health           17\n                                  No Issue Reported       11\n                                  Poor Time Management    20\n                                  Sickness                19\nLength: 72, dtype: int64\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1753789231159
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['identified_issues'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "No Issue Reported       183\nLate Enrollment         146\nMental Health           100\nDeath in Family          93\nPoor Time Management     89\nSickness                 87\nName: identified_issues, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1753789231226
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_realistic_issues_adjusted(row):\n",
        "    academic_status = str(row['academic_status']).strip().lower()\n",
        "    cohort = str(row['student_cohort']).strip().lower()\n",
        "    current_issues = row['identified_issues']\n",
        "\n",
        "    if academic_status == 'satisfactory':\n",
        "        if cohort in ['new', 'first year']:\n",
        "            # Keep ~25% Late Enrollment for New/First Year\n",
        "            if np.random.rand() < 0.25:\n",
        "                return \"Late Enrollment\"\n",
        "            else:\n",
        "                return \"No Issue Reported\"\n",
        "        else:\n",
        "            # Other satisfactory students targeted ~30% with issues\n",
        "            if current_issues == \"No Issue Reported\":\n",
        "                # Assign issues to about 30% of those who currently have no issues\n",
        "                if np.random.rand() < 0.30:\n",
        "                    num_issues = np.random.choice([1, 2], p=[0.7, 0.3])\n",
        "                    sampled_issues = np.random.choice(known_issues_list, size=num_issues, replace=False)\n",
        "                    return '; '.join(sorted(sampled_issues))\n",
        "                else:\n",
        "                    return \"No Issue Reported\"\n",
        "            else:\n",
        "                # For students with current issues: retain about 30-40% of them,\n",
        "                # the rest lose the issue (set to No Issue Reported) to reduce prevalence\n",
        "                if np.random.rand() < 0.35:\n",
        "                    return current_issues\n",
        "                else:\n",
        "                    return \"No Issue Reported\"\n",
        "    else:\n",
        "        # For non-Satisfactory, keep as is\n",
        "        return current_issues\n",
        "\n",
        "# Reapply this adjusted function\n",
        "df['identified_issues'] = df.apply(assign_realistic_issues_adjusted, axis=1)\n"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1753789231293
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Filter \"New\" and \"First year\" Satisfactory students\n",
        "mask_new_first = (\n",
        "    df['academic_status'].str.strip().str.lower() == 'satisfactory') & \\\n",
        "    (df['student_cohort'].str.strip().str.lower().isin(['new', 'first year']))\n",
        "df_new_first = df[mask_new_first]\n",
        "\n",
        "# Check total, number and percentage with \"Late Enrollment\"\n",
        "late_enroll_count = (df_new_first['identified_issues'] == 'Late Enrollment').sum()\n",
        "total_new_first = len(df_new_first)\n",
        "late_enroll_pct = late_enroll_count / total_new_first * 100\n",
        "print(f\"Late Enrollment in New/First Year Satisfactory: {late_enroll_count}/{total_new_first} ({late_enroll_pct:.1f}%)\")\n",
        "\n",
        "# Distribution of all identified issues in this subgroup\n",
        "print(\"\\nAll identified issues in New/First Year Satisfactory cohort:\")\n",
        "print(df_new_first['identified_issues'].value_counts())\n",
        "\n",
        "# 2. Satisfactory students overall — how many have issues, and what are they?\n",
        "mask_satisf = df['academic_status'].str.strip().str.lower() == 'satisfactory'\n",
        "df_satisf = df[mask_satisf]\n",
        "\n",
        "# How many have an issue (not \"No Issue Reported\")\n",
        "has_issue = (df_satisf['identified_issues'] != \"No Issue Reported\").sum()\n",
        "satisf_total = len(df_satisf)\n",
        "has_issue_pct = has_issue / satisf_total * 100\n",
        "print(f\"\\nSatisfactory students with any issue: {has_issue}/{satisf_total} ({has_issue_pct:.1f}%)\")\n",
        "print(\"\\nSatisfactory identified issues value counts:\")\n",
        "print(df_satisf['identified_issues'].value_counts())\n",
        "\n",
        "# 3. New/First Year outlier check: how many have other issues (not Late Enrollment or No Issue)\n",
        "outlier_mask = (\n",
        "    mask_new_first & \n",
        "    (~df['identified_issues'].isin(['No Issue Reported', 'Late Enrollment']))\n",
        ")\n",
        "print(\"\\nOther issues (not Late Enrollment/No Issue) for New/First Year Satisfactory:\")\n",
        "print(df.loc[outlier_mask, 'identified_issues'].value_counts())\n",
        "\n",
        "# 4. For non-Satisfactory students, what issues do they have?\n",
        "mask_non_satisf = df['academic_status'].str.strip().str.lower() != \"satisfactory\"\n",
        "print(\"\\nNon-Satisfactory issues value counts:\")\n",
        "print(df.loc[mask_non_satisf, 'identified_issues'].value_counts())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Late Enrollment in New/First Year Satisfactory: 49/182 (26.9%)\n\nAll identified issues in New/First Year Satisfactory cohort:\nNo Issue Reported    133\nLate Enrollment       49\nName: identified_issues, dtype: int64\n\nSatisfactory students with any issue: 179/621 (28.8%)\n\nSatisfactory identified issues value counts:\nNo Issue Reported                       442\nLate Enrollment                          72\nMental Health                            30\nDeath in Family                          27\nSickness                                 23\nPoor Time Management                     21\nNon Submission                            2\nAttendance; Poor Time Management          2\nConcern for Welfare; Death in Family      1\nConcern for Welfare                       1\nName: identified_issues, dtype: int64\n\nOther issues (not Late Enrollment/No Issue) for New/First Year Satisfactory:\nSeries([], Name: identified_issues, dtype: int64)\n\nNon-Satisfactory issues value counts:\nLate Enrollment         16\nDeath in Family         16\nMental Health           16\nSickness                14\nPoor Time Management    11\nNo Issue Reported        4\nName: identified_issues, dtype: int64\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1753789231418
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Clean Self Assessment Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['self_assessment'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": "No     360\nYes    338\nName: self_assessment, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1753789231507
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[~df['student_cohort'].isin(['First Year', 'New']), 'self_assessment'] = 'n/a'"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1753789231589
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['self_assessment'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "n/a    589\nYes     57\nNo      52\nName: self_assessment, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1753789231689
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flag Students (High Risk, Medium Risk, Low Risk)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def risk_level_week3(row):\n",
        "    score = 0\n",
        "\n",
        "    if row['academic_status'] in ['Academic Caution', 'Conditional', 'Excluded']:\n",
        "        score += 1\n",
        "\n",
        "    if row['failed_subjects'] > 0:\n",
        "        score += 1\n",
        "\n",
        "    if row['student_cohort'] in ['New', 'First year']:\n",
        "        score += 1\n",
        "\n",
        "    if pd.notna(row['attendance_1']) and row['attendance_1'] <= 50:\n",
        "        score += 1\n",
        "\n",
        "    if pd.notna(row['subject_1_assess_1']) and row['subject_1_assess_1'] < 50:\n",
        "        score += 1\n",
        "\n",
        "    if row['identified_issues'] != 'No issues identified':\n",
        "        score += 1\n",
        "\n",
        "    # Assign level\n",
        "    if score >= 3:\n",
        "        return 'High'\n",
        "    elif score == 2:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'\n"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1753789231804
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['risk_assessments'] = df.apply(risk_level_week3, axis=1)"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1753789231886
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['risk_assessments'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "Low       416\nMedium    187\nHigh       95\nName: risk_assessments, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1753789231958
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts_by_cohort = df.groupby(['student_cohort', 'risk_assessments']).size().unstack(fill_value=0)\n",
        "print(counts_by_cohort)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "risk_assessments  High  Low  Medium\nstudent_cohort                     \nContinuing           9   67       4\nExcluded             5    0       0\nFirst year          23    0      69\nLOA                 16   78       5\nNew                 16    0      93\nReturn to Study     25   76       6\nSRI to JCUB          0   97       7\nTransferred          1   98       3\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1753789232020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel('flagged_students.xlsx', index = False)"
      ],
      "outputs": [],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1753791902376
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}